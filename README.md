# FGSM-attack-against-MalConv
Create Adversarial Examples to evade detection by MalConv used in [Machine Learning Static Evasion Competition](https://github.com/endgameinc/malware_evasion_competition).

I've used only MalConv model as a target and used following paper as a reference.

[Deceiving End-to-End Deep Learning Malware Detectors using Adversarial Examples](https://arxiv.org/abs/1802.04528)

Many thanks.
